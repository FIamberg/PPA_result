import streamlit as st
import pandas as pd
import numpy as np
from google.oauth2 import service_account
from googleapiclient.discovery import build
from typing import Optional, List, Dict, Any, Tuple
import logging
import plotly.express as px
import warnings
from datetime import datetime, timedelta, date
import calendar
import json
import os
from io import StringIO

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –∫—ç—à–µ
warnings.filterwarnings('ignore', message='file_cache is unavailable when using oauth2client >= 4.0.0')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
NUMERIC_COLUMNS = ['—Ä—É–∫–∏', 'RB%_PLAYER', 'Rake_USD_PLAYER', 'RB_USD_PLAYER', 'Win_USD_PLAYER', 'Profit_PLAYER']
SPREADSHEET_ID = '1vtB1IFryFOiM13EfPFD60kQ69KaYxLQtrtB4KOsoZKo'
CACHE_PATH = '.streamlit/cache/'
CACHE_FILE = 'data_cache.json'

def get_date_ranges() -> Dict[str, Tuple[date, date]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–∞—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    
    Returns:
        Dict[str, Tuple[date, date]]: –°–ª–æ–≤–∞—Ä—å —Å –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º–∏ –¥–∞—Ç
    """
    today = date.today()
    first_day_current = today.replace(day=1)
    thirty_days_ago = today - timedelta(days=30)
    
    return {
        'current_month': (first_day_current, today),
        'last_30_days': (thirty_days_ago, today)
    }

class DataCache:
    def __init__(self):
        self.cache_path = CACHE_PATH
        self.cache_file = CACHE_FILE
        os.makedirs(self.cache_path, exist_ok=True)
    
    def save_to_cache(self, data: pd.DataFrame):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à
        
        Args:
            data (pd.DataFrame): DataFrame –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        try:
            data_copy = data.copy()
            date_column = data_copy.columns[0]
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
            data_copy[date_column] = data_copy[date_column].apply(
                lambda x: x.isoformat() if isinstance(x, date) else None
            )
            
            cache_data = {
                'timestamp': datetime.now().isoformat(),
                'data': data_copy.to_json(date_format='iso', orient='split')
            }
            
            with open(os.path.join(self.cache_path, self.cache_file), 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False)
                
            logger.info("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –∫—ç—à: {e}")
            raise
    
    def load_from_cache(self) -> Optional[pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞
        
        Returns:
            Optional[pd.DataFrame]: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π DataFrame –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            cache_file = os.path.join(self.cache_path, self.cache_file)
            if not os.path.exists(cache_file):
                logger.info("–ö—ç—à-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∫—ç—à–∞ (24 —á–∞—Å–∞)
            cache_timestamp = datetime.fromisoformat(cache_data['timestamp'])
            if datetime.now() - cache_timestamp > timedelta(days=1):
                logger.info("–ö—ç—à —É—Å—Ç–∞—Ä–µ–ª")
                return None
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º StringIO –¥–ª—è —á—Ç–µ–Ω–∏—è JSON
            df = pd.read_json(StringIO(cache_data['data']), orient='split')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ–±—ä–µ–∫—Ç—ã date
            date_column = df.columns[0]
            df[date_column] = pd.to_datetime(df[date_column]).dt.date
            
            logger.info("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
            return df
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ –∫—ç—à–∞: {e}")
            return None
    
    def clear_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à"""
        try:
            cache_file = os.path.join(self.cache_path, self.cache_file)
            if os.path.exists(cache_file):
                os.remove(cache_file)
                logger.info("–ö—ç—à —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞: {e}")
            raise

    def get_cache_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∫—ç—à–∞
        
        Returns:
            Dict[str, Any]: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫—ç—à–µ
        """
        try:
            cache_file = os.path.join(self.cache_path, self.cache_file)
            if not os.path.exists(cache_file):
                return {
                    'exists': False,
                    'size': 0,
                    'last_modified': None,
                    'age_hours': None
                }
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            timestamp = datetime.fromisoformat(cache_data['timestamp'])
            age = datetime.now() - timestamp
            
            return {
                'exists': True,
                'size': os.path.getsize(cache_file),
                'last_modified': timestamp,
                'age_hours': age.total_seconds() / 3600
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫—ç—à–µ: {e}")
            return {
                'exists': False,
                'size': 0,
                'last_modified': None,
                'age_hours': None,
                'error': str(e)
            }

class DataLoader:
    def __init__(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö.
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Google Sheets –∏ —Å–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç –∫–µ—à–∞.
        """
        try:
            self.credentials = service_account.Credentials.from_service_account_info(
                st.secrets["gcp_service_account"],
                scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"],
            )
            self.service = build(
                "sheets", 
                "v4", 
                credentials=self.credentials,
                cache_discovery=False
            )
            self.cache = DataCache()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DataLoader: {e}")
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Sheets")

    def _format_date(self, date_str: str) -> date:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–∞—Ç—ã –≤ –æ–±—ä–µ–∫—Ç date.
        
        Args:
            date_str: –°—Ç—Ä–æ–∫–∞ —Å –¥–∞—Ç–æ–π –∏–ª–∏ –æ–±—ä–µ–∫—Ç date
            
        Returns:
            date: –û–±—ä–µ–∫—Ç datetime.date –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        if isinstance(date_str, date):
            return date_str
            
        if pd.isna(date_str):
            return None
            
        try:
            # –ü—Ä–æ–±—É–µ–º —Ñ–æ—Ä–º–∞—Ç DD.MM.YYYY
            return datetime.strptime(str(date_str).strip(), '%d.%m.%Y').date()
        except ValueError:
            try:
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã —á–µ—Ä–µ–∑ pandas
                return pd.to_datetime(date_str).date()
            except:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—É: {date_str}")
                return None

    def _process_numeric_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã DataFrame.
        
        Args:
            df: –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
            
        Returns:
            DataFrame: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame
        """
        try:
            df = df.copy()
            
            for col in NUMERIC_COLUMNS:
                if col in df.columns:
                    df[col] = (df[col]
                              .replace('', np.nan)
                              .replace('-', np.nan)
                              .str.replace('\xa0', '', regex=False)
                              .str.replace(',', '.', regex=False)
                              .str.replace(' ', '', regex=False)
                              .pipe(pd.to_numeric, errors='coerce'))
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —Ç—Ä–µ–Ω–µ—Ä = '0'
            df = df[df['–¢—Ä–µ–Ω–µ—Ä'] != '0']
            
            return df
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {e}")
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö")
            return df

    def _fetch_from_sheets(self) -> Optional[pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets.
        
        Returns:
            Optional[pd.DataFrame]: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π DataFrame –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets")
            sheet = self.service.spreadsheets()
            result = sheet.values().get(
                spreadsheetId=SPREADSHEET_ID,
                range="pivot_result"
            ).execute()
            values = result.get("values", [])
            
            if not values:
                st.error("–î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ Google Sheets")
                return None
            
            df = pd.DataFrame(values[1:], columns=values[0])
            
            date_column = df.columns[0]
            df[date_column] = df[date_column].apply(self._format_date)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏
            df = df.dropna(subset=[date_column])
            
            return self._process_numeric_columns(df)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets: {e}")
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            return None

    def _validate_dataframe(self, df: pd.DataFrame) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ DataFrame.
        
        Args:
            df: DataFrame –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            bool: True –µ—Å–ª–∏ DataFrame –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        if df is None or df.empty:
            return False
            
        required_columns = ['–¢—Ä–µ–Ω–µ—Ä', 'nickname', 'club_name'] + NUMERIC_COLUMNS
        for col in required_columns:
            if col not in df.columns:
                logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü: {col}")
                return False
                
        date_column = df.columns[0]
        if df[date_column].isna().all():
            logger.error("–í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–µ –¥–∞—Ç—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
            return False
            
        return True

    def load_data(self, force_reload: bool = False) -> Optional[pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–µ—à–∞ –∏–ª–∏ Google Sheets.
        
        Args:
            force_reload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ Google Sheets
            
        Returns:
            Optional[pd.DataFrame]: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π DataFrame –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            df = None
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫–µ—à–∞, –µ—Å–ª–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
            if not force_reload:
                df = self.cache.load_from_cache()
                if df is not None:
                    logger.info("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫–µ—à–∞")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –∫–µ—à–∞
                    date_column = df.columns[0]
                    df[date_column] = df[date_column].apply(self._format_date)
                    df = df.dropna(subset=[date_column])
                    
                    if self._validate_dataframe(df):
                        return df
                    else:
                        logger.warning("–î–∞–Ω–Ω—ã–µ –≤ –∫–µ—à–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã")
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –∫–µ—à–µ –∏–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ Google Sheets
            df = self._fetch_from_sheets()
            
            if df is not None and self._validate_dataframe(df):
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –∫–µ—à
                self.cache.save_to_cache(df)
                logger.info("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫–µ—à")
                return df
            else:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            return None

    def clear_cache(self) -> bool:
        """
        –û—á–∏—â–∞–µ—Ç –∫–µ—à –¥–∞–Ω–Ω—ã—Ö.
        
        Returns:
            bool: True –µ—Å–ª–∏ –æ—á–∏—Å—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        try:
            self.cache.clear_cache()
            logger.info("–ö–µ—à —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω")
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫–µ—à–∞: {e}")
            return False
    def __init__(self):
        try:
            self.credentials = service_account.Credentials.from_service_account_info(
                st.secrets["gcp_service_account"],
                scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"],
            )
            self.service = build(
                "sheets", 
                "v4", 
                credentials=self.credentials,
                cache_discovery=False
            )
            self.cache = DataCache()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DataLoader: {e}")
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Sheets")

    def _format_date(self, date_str: str) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        try:
            return pd.to_datetime(date_str, format='%d.%m.%Y').date()
        except:
            try:
                return pd.to_datetime(date_str).date()
            except:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—É: {date_str}")
                return None

    def load_data(self, force_reload: bool = False) -> Optional[pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞ –∏–ª–∏ Google Sheets
        
        Args:
            force_reload (bool): –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ Google Sheets
        """
        try:
            if not force_reload:
                cached_data = self.cache.load_from_cache()
                if cached_data is not None:
                    logger.info("–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
                    return cached_data
            
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets")
            sheet = self.service.spreadsheets()
            result = sheet.values().get(
                spreadsheetId=SPREADSHEET_ID,
                range="pivot_result"
            ).execute()
            values = result.get("values", [])
            
            if not values:
                st.error("–î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return None
            
            df = pd.DataFrame(values[1:], columns=values[0])
            date_column = df.columns[0]
            df[date_column] = df[date_column].apply(self._format_date)
            
            processed_df = self._process_numeric_columns(df)
            if processed_df is not None:
                self.cache.save_to_cache(processed_df)
                logger.info("–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à")
            
            return processed_df
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            return None

    def _process_numeric_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã DataFrame"""
        try:
            df = df.copy()
            for col in NUMERIC_COLUMNS:
                if col in df.columns:
                    df[col] = (df[col]
                              .replace('', np.nan)
                              .str.replace('\xa0', '')
                              .str.replace(',', '.')
                              .pipe(pd.to_numeric, errors='coerce'))
            df = df[df['–¢—Ä–µ–Ω–µ—Ä'] != '0']
            return df
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {e}")
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö")
            return df

class StreamlitApp:
    def __init__(self):
        st.set_page_config(
            page_title="Google Sheets Viewer",
            page_icon="üìä",
            layout="wide"
        )
        self.data_loader = DataLoader()
        self.data = None
        self.filtered_data = None
        self.date_ranges = get_date_ranges()

    def setup_filters(self) -> Dict[str, Any]:
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        with st.sidebar:
            st.header("–§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–∞–º")
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–∞—Ç—ã –≤ DataFrame –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ç–∏–ø–∞
            date_column = self.data.columns[0]
            self.data[date_column] = pd.to_datetime(self.data[date_column]).dt.date
            
            min_date = self.data[date_column].min()
            max_date = self.data[date_column].max()
            
            # –ö–Ω–æ–ø–∫–∏ –±—ã—Å—Ç—Ä–æ–≥–æ –≤—ã–±–æ—Ä–∞ –ø–µ—Ä–∏–æ–¥–∞
            date_filter_type = st.radio(
                "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥:",
                ["–¢–µ–∫—É—â–∏–π –º–µ—Å—è—Ü", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π", "–í—Å–µ –≤—Ä–µ–º—è", "–í—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥"]
            )
            
            if date_filter_type == "–í—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥":
                col1, col2 = st.columns(2)
                with col1:
                    start_date = st.date_input(
                        "–ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞",
                        value=min_date,
                        min_value=min_date,
                        max_value=max_date,
                        format="DD.MM.YYYY"
                    )
                with col2:
                    end_date = st.date_input(
                        "–ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞",
                        value=max_date,
                        min_value=min_date,
                        max_value=max_date,
                        format="DD.MM.YYYY"
                    )
            else:
                if date_filter_type == "–¢–µ–∫—É—â–∏–π –º–µ—Å—è—Ü":
                    start_date = self.date_ranges['current_month'][0]
                    end_date = self.date_ranges['current_month'][1]
                elif date_filter_type == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π":
                    start_date = self.date_ranges['last_30_days'][0]
                    end_date = self.date_ranges['last_30_days'][1]
                else:  # –í—Å–µ –≤—Ä–µ–º—è
                    start_date = min_date
                    end_date = max_date
            
            st.markdown("---")
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –¥–∞—Ç—ã –∫ –Ω—É–∂–Ω–æ–º—É —Ç–∏–ø—É –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            period_filtered_data = self.data[
                (self.data[date_column] >= pd.to_datetime(start_date).date()) &
                (self.data[date_column] <= pd.to_datetime(end_date).date())
            ]
            
            # –§–∏–ª—å—Ç—Ä –ø–æ —Ç—Ä–µ–Ω–µ—Ä—É
            all_coaches = ['–í—Å–µ'] + sorted(period_filtered_data['–¢—Ä–µ–Ω–µ—Ä'].unique().tolist())
            selected_coach = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ç—Ä–µ–Ω–µ—Ä–∞",
                all_coaches,
                index=0
            )
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–≥—Ä–æ–∫–æ–≤
            if selected_coach != '–í—Å–µ':
                players_data = period_filtered_data[period_filtered_data['–¢—Ä–µ–Ω–µ—Ä'] == selected_coach]
            else:
                players_data = period_filtered_data
                
            # –§–∏–ª—å—Ç—Ä –ø–æ –∏–≥—Ä–æ–∫—É
            all_players = ['–í—Å–µ'] + sorted(players_data['nickname'].unique().tolist())
            selected_player = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∏–≥—Ä–æ–∫–∞",
                all_players,
                index=0
            )
            
            return {
                "coach": selected_coach,
                "player": selected_player,
                "grouping": ['–¢—Ä–µ–Ω–µ—Ä', 'nickname'],
                "start_date": pd.to_datetime(start_date).date(),
                "end_date": pd.to_datetime(end_date).date()
            }

    def apply_filters(self, params: Dict[str, Any]) -> pd.DataFrame:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –∫ –¥–∞–Ω–Ω—ã–º
        """
        filtered_data = self.data.copy()
        date_column = filtered_data.columns[0]
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        filtered_data[date_column] = pd.to_datetime(filtered_data[date_column]).dt.date
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        filtered_data = filtered_data[
            (filtered_data[date_column] >= params["start_date"]) &
            (filtered_data[date_column] <= params["end_date"])
        ]
        
        if params["coach"] != '–í—Å–µ':
            filtered_data = filtered_data[filtered_data['–¢—Ä–µ–Ω–µ—Ä'] == params["coach"]]
        
        if params["player"] != '–í—Å–µ':
            filtered_data = filtered_data[filtered_data['nickname'] == params["player"]]
        
        return filtered_data

    def process_and_display_data(self, filtered_data: pd.DataFrame, params: Dict[str, Any]):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
        agg_dict = {
            'Profit_PLAYER': 'sum',
            'Win_USD_PLAYER': 'sum',
            'RB_USD_PLAYER': 'sum',
            '—Ä—É–∫–∏': 'sum',
            'Rake_USD_PLAYER': 'sum'
        }
        
        grouped_data = (filtered_data
                       .groupby(params["grouping"], as_index=False)
                       .agg(agg_dict)
                       .round(0)
                       .sort_values(by='Profit_PLAYER', ascending=False))
        
        grouped_data.insert(0, "–í—ã–±—Ä–∞—Ç—å", False)
        
        col1, col2 = st.columns([4, 4])
        
        with col1:
            st.subheader("–°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            
            config = {
                "–í—ã–±—Ä–∞—Ç—å": st.column_config.CheckboxColumn(
                    "–í—ã–±—Ä–∞—Ç—å",
                    help="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏",
                    default=False,
                )
            }
            
            edited_df = st.data_editor(
                grouped_data,
                hide_index=True,
                column_config=config,
                disabled=grouped_data.columns.difference(["–í—ã–±—Ä–∞—Ç—å"]).tolist(),
                key="data_editor",
                height=600,
                use_container_width=True
            )
            
            selected_rows = edited_df[edited_df["–í—ã–±—Ä–∞—Ç—å"]]
            
            if not selected_rows.empty:
                filtered_for_visualization = pd.DataFrame()
                for _, row in selected_rows.iterrows():
                    mask = pd.Series(True, index=filtered_data.index)
                    for group_col in params["grouping"]:
                        mask &= filtered_data[group_col] == row[group_col]
                    filtered_for_visualization = pd.concat([filtered_for_visualization, filtered_data[mask]])
                
                filtered_grouped_data = selected_rows
            else:
                filtered_grouped_data = grouped_data
                filtered_for_visualization = filtered_data
            
            filtered_grouped_data = filtered_grouped_data.drop(columns=["–í—ã–±—Ä–∞—Ç—å"])
            
            st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª—É–±–∞–º")
            
            club_data = (filtered_for_visualization
                        .groupby('club_name', as_index=False)
                        .agg(agg_dict)
                        .round(0)
                        .sort_values(by='Profit_PLAYER', ascending=False))
            

                
                
            club_data = club_data.rename(columns={
                'club_name': '–ö–ª—É–±',
                'Profit_PLAYER': '–ü—Ä–æ—Ñ–∏—Ç',
                'Win_USD_PLAYER': '–í—ã–∏–≥—Ä—ã—à',
                'RB_USD_PLAYER': '–†–ë',
                '—Ä—É–∫–∏': '–†—É–∫–∏',
                'Rake_USD_PLAYER': '–†–µ–π–∫'
            })
            
            totals = club_data.sum(numeric_only=True).round(0)
            totals = pd.DataFrame([totals], columns=club_data.columns[1:])
            totals.insert(0, '–ö–ª—É–±', '–ò–¢–û–ì–û')
            club_data = pd.concat([club_data, totals], ignore_index=True)
            
            st.dataframe(
                club_data,
                hide_index=True,
                use_container_width=True,
                column_config={
                    '–ö–ª—É–±': st.column_config.TextColumn('–ö–ª—É–±'),
                    '–ü—Ä–æ—Ñ–∏—Ç': st.column_config.NumberColumn('–ü—Ä–æ—Ñ–∏—Ç', format="%.0f", help="–û–±—â–∏–π –ø—Ä–æ—Ñ–∏—Ç"),
                    '–í—ã–∏–≥—Ä—ã—à': st.column_config.NumberColumn('–í—ã–∏–≥—Ä—ã—à', format="%.0f", help="–û–±—â–∏–π –≤—ã–∏–≥—Ä—ã—à"),
                    '–†–ë': st.column_config.NumberColumn('–†–ë', format="%.0f", help="–û–±—â–∏–π —Ä–µ–π–∫–±–µ–∫"),
                    '–†—É–∫–∏': st.column_config.NumberColumn('–†—É–∫–∏', format="%.0f", help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ã–≥—Ä–∞–Ω–Ω—ã—Ö —Ä—É–∫"),
                    '–†–µ–π–∫': st.column_config.NumberColumn('–†–µ–π–∫', format="%.0f", help="–û–±—â–∏–π —Ä–µ–π–∫")
                }
            )
        
        with col2:
            metric_cols = st.columns(5)
            
            total_profit = float(filtered_grouped_data['Profit_PLAYER'].sum())
            total_win = float(filtered_grouped_data['Win_USD_PLAYER'].sum())
            total_rb = float(filtered_grouped_data['RB_USD_PLAYER'].sum())
            total_hands = float(filtered_grouped_data['—Ä—É–∫–∏'].sum())
            total_rake = float(filtered_grouped_data['Rake_USD_PLAYER'].sum())
            
            metric_cols[0].metric("Profit", f"${total_profit:,.0f}")
            metric_cols[1].metric("Win", f"${total_win:,.0f}")
            metric_cols[2].metric("RB", f"${total_rb:,.0f}")
            metric_cols[3].metric("–†—É–∫–∏", f"{total_hands:,.0f}")
            metric_cols[4].metric("Rake", f"${total_rake:,.0f}")
            
            self.display_visualizations(filtered_for_visualization, params)

    def display_visualizations(self, filtered_data: pd.DataFrame, params: Dict[str, Any]):
        """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
        if len(filtered_data) > 1:
            date_column = filtered_data.columns[0]
            
            daily_data = filtered_data.groupby(date_column).agg({
                'Profit_PLAYER': 'sum',
                'Win_USD_PLAYER': 'sum',
                '—Ä—É–∫–∏': 'sum'
            }).reset_index()
            
            daily_data = daily_data.sort_values(by=date_column)
            daily_data['Profit_PLAYER_cum'] = daily_data['Profit_PLAYER'].cumsum()
            daily_data['Win_USD_PLAYER_cum'] = daily_data['Win_USD_PLAYER'].cumsum()
            
            fig = px.line(
                daily_data,
                x=date_column,
                y=['Profit_PLAYER_cum', 'Win_USD_PLAYER_cum'],
                labels={
                    'value': '–ó–Ω–∞—á–µ–Ω–∏–µ',
                    'variable': '–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å',
                    date_column: '–î–∞—Ç–∞'
                }
            )
            
            fig.update_traces(
                line=dict(color='rgb(26,118,217)', width=4),
                name='Profit',
                selector=dict(name='Profit_PLAYER_cum')
            )
            fig.update_traces(
                line=dict(color='rgb(240,170,31)', width=2),
                name='Win',
                selector=dict(name='Win_USD_PLAYER_cum')
            )
            
            fig.add_bar(
                x=daily_data[date_column],
                y=daily_data['—Ä—É–∫–∏'],
                name='–†—É–∫–∏',
                yaxis='y2',
                marker_color='rgb(140,140,140)',
                opacity=0.3
            )
            
            fig.update_layout(
                yaxis2=dict(
                    title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä—É–∫',
                    overlaying='y',
                    side='right',
                    showgrid=False
                ),
                yaxis=dict(
                    title='–ó–Ω–∞—á–µ–Ω–∏–µ, $',
                    side='left',
                    showgrid=True
                ),
                hovermode='x unified',
                showlegend=True,
                legend=dict(
                    yanchor="top",
                    y=0.99,
                    xanchor="left",
                    x=0.01
                ),
                height=600
            )
            
            st.plotly_chart(fig, use_container_width=True)

    def load_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        col1, col2 = st.columns([6, 1])
        with col2:
            if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ", key="refresh_data"):
                with st.spinner("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö..."):
                    self.data = self.data_loader.load_data(force_reload=True)
                    st.success("–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")
                    st.experimental_rerun()
        
        if self.data is None:
            with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                self.data = self.data_loader.load_data()

    def run(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"""
        st.title("–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏–≥—Ä–æ–∫–æ–≤")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        self.load_data()
        if self.data is None:
            return
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        params = self.setup_filters()
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        filtered_data = self.apply_filters(params)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        self.process_and_display_data(filtered_data, params)

if __name__ == "__main__":
    app = StreamlitApp()
    app.run()
